{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mercari/test.tsv\n",
      "/kaggle/input/mercari/train.tsv\n",
      "/kaggle/input/mercari/test_stg2.tsv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/mercari'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#importing train data\n",
    "raw_data=pd.read_csv(\"../input/mercari/train.tsv\",sep=\"\\t\")\n",
    "\n",
    "test_data=pd.read_csv(\"../input/mercari/test_stg2.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all text to lower case\n",
    "raw_data['name']=raw_data['name'].str.lower()\n",
    "test_data['name']=test_data['name'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting all category names to lower case\n",
    "raw_data['category_name']=raw_data['category_name'].str.lower()\n",
    "test_data['category_name']=test_data['category_name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting category into three columns\n",
    "# https://www.geeksforgeeks.org/python-pandas-split-strings-into-two-list-columns-using-str-split/\n",
    "sub_category_columns=raw_data['category_name'].str.split(\"/\",expand=True,n=2)\n",
    "sub_category_columns_test=test_data['category_name'].str.split(\"/\",expand=True,n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['category']=sub_category_columns[0]\n",
    "raw_data['subcategory1']=sub_category_columns[1]\n",
    "raw_data['subcategory2']=sub_category_columns[2]\n",
    "\n",
    "test_data['category']=sub_category_columns_test[0]\n",
    "test_data['subcategory1']=sub_category_columns_test[1]\n",
    "test_data['subcategory2']=sub_category_columns_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting brand names to lower case\n",
    "raw_data['brand_name']=raw_data['brand_name'].str.lower()\n",
    "test_data['brand_name']=test_data['brand_name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4810\n",
      "4809\n"
     ]
    }
   ],
   "source": [
    "# trying to impute brand name\n",
    "list_of_brand_names=raw_data['brand_name'].unique().tolist()\n",
    "print(len(list_of_brand_names))\n",
    "cleaned_brand_list = [x for x in list_of_brand_names if str(x) != 'nan']\n",
    "print(len(cleaned_brand_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand_replace(column):\n",
    "    for i in cleaned_brand_list:\n",
    "        if i in str(column).split():\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Newbrand']=raw_data['name'].apply(brand_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['brand_name']=np.where(raw_data['brand_name'].isnull(),raw_data['Newbrand'],raw_data['brand_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['brand_name'].fillna(value=\"Not Present\", inplace=True)\n",
    "test_data['brand_name'].fillna(value=\"Not Present\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all item descritpion to lower case\n",
    "raw_data['item_description']=raw_data['item_description'].str.lower()\n",
    "test_data['item_description']=test_data['item_description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_zero_price_removed=raw_data[raw_data.price!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "raw_data_zero_price_removed['item_description'].fillna(value='Not Present',inplace=True)\n",
    "test_data['item_description'].fillna(value='Not Present',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_zero_price_removed['category'].fillna(value='Not Present',inplace=True)\n",
    "raw_data_zero_price_removed['subcategory1'].fillna(value='Not Present',inplace=True)\n",
    "raw_data_zero_price_removed['subcategory2'].fillna(value='Not Present',inplace=True)\n",
    "\n",
    "\n",
    "test_data['category'].fillna(value='Not Present',inplace=True)\n",
    "test_data['subcategory1'].fillna(value='Not Present',inplace=True)\n",
    "test_data['subcategory2'].fillna(value='Not Present',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "raw_data_zero_price_removed['log_price']=np.log(raw_data_zero_price_removed['price']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=raw_data_zero_price_removed.log_price\n",
    "x=raw_data_zero_price_removed.drop(['train_id','item_condition_id','category_name','Newbrand','log_price'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords=stopwords.words('english')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1481661/1481661 [01:00<00:00, 24332.04it/s]\n",
      "100%|██████████| 1481661/1481661 [02:47<00:00, 8834.86it/s]\n",
      "100%|██████████| 3460725/3460725 [02:23<00:00, 24065.93it/s]\n",
      "100%|██████████| 3460725/3460725 [06:28<00:00, 8909.65it/s]\n",
      "100%|██████████| 1481661/1481661 [00:44<00:00, 33654.91it/s]\n",
      "100%|██████████| 3460725/3460725 [01:44<00:00, 32989.54it/s]\n"
     ]
    }
   ],
   "source": [
    "len(stopwords)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "preprocessed_name_train = []\n",
    "for sentance in tqdm(x['name'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    \n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    preprocessed_name_train.append(sent.lower().strip())\n",
    "\n",
    "preprocessed_description_train = []\n",
    "for sentance in tqdm(x['item_description'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    \n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    preprocessed_description_train.append(sent.lower().strip())\n",
    "    \n",
    "preprocessed_name_test = []\n",
    "for sentance in tqdm(test_data['name'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    \n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    preprocessed_name_test.append(sent.lower().strip())\n",
    "    \n",
    "preprocessed_description_test = []\n",
    "for sentance in tqdm(test_data['item_description'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    \n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    preprocessed_description_test.append(sent.lower().strip())\n",
    "    \n",
    "preprocessed_brand_name_train = []\n",
    "for sentance in tqdm(x['brand_name'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    \n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    preprocessed_brand_name_train.append(sent.lower().strip())\n",
    "    \n",
    "preprocessed_brand_name_test = []\n",
    "for sentance in tqdm(test_data['brand_name'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    \n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    preprocessed_brand_name_test.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train Name feature:  (1481661, 17732)\n",
      "Shape of test Name feature:  (3460725, 17732)\n"
     ]
    }
   ],
   "source": [
    "count_name = CountVectorizer(min_df=10)\n",
    "train_name_vec = count_name.fit_transform(x[\"name\"])\n",
    "test_name_vec = count_name.transform(test_data[\"name\"])\n",
    "print(\"Shape of train Name feature: \",train_name_vec.shape)\n",
    "print(\"Shape of test Name feature: \",test_name_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after TFIDF vectorizer  (1481661, 50000)\n",
      "Shape of matrix after TFIDF vectorizer  (3460725, 50000)\n"
     ]
    }
   ],
   "source": [
    "## TFIDF on description\n",
    "vectorizer_desc_tfidf = TfidfVectorizer(min_df=10,max_features=50000,ngram_range=(1,3))\n",
    "desc_tfidf_train = vectorizer_desc_tfidf.fit_transform(preprocessed_description_train)\n",
    "\n",
    "print(\"Shape of matrix after TFIDF vectorizer \",desc_tfidf_train.shape)\n",
    "\n",
    "## TFIDF on description test set\n",
    "desc_tfidf_test = vectorizer_desc_tfidf.transform(preprocessed_description_test)\n",
    "\n",
    "print(\"Shape of matrix after TFIDF vectorizer \",desc_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand encoders\n"
     ]
    }
   ],
   "source": [
    "# featurizing brand name\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "print(\"Brand encoders\")\n",
    "vect_brand = LabelBinarizer(sparse_output=True)\n",
    "\n",
    "encoder_brand_train = vect_brand.fit_transform(x[\"brand_name\"])\n",
    "encoder_brand_test= vect_brand.transform(test_data[\"brand_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "cat_features = ['category', 'subcategory1', 'subcategory2']\n",
    "count_enc = ce.CountEncoder()\n",
    "count_encoded_train = count_enc.fit_transform(x[cat_features])\n",
    "count_encoded_test=count_enc.transform(test_data[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_count_encoded=x.join(count_encoded_train.add_suffix(\"_count\"))\n",
    "x_test_count_encoded=test_data.join(count_encoded_test.add_suffix(\"_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_count_encoded['category_count'].fillna(0,inplace=True)\n",
    "x_test_count_encoded['subcategory1_count'].fillna(0,inplace=True)\n",
    "x_test_count_encoded['subcategory2_count'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##brand average price\n",
    "avg_brand_price=pd.DataFrame(x_train_count_encoded.groupby('brand_name',as_index=False)['price'].mean())\n",
    "\n",
    "avg_brand_price['log_price']=np.log(avg_brand_price['price']+1)\n",
    "\n",
    "#adding average price of each brand in x_train\n",
    "x_train_count_encoded=pd.merge(x_train_count_encoded,avg_brand_price[['brand_name','log_price']],how='left',on='brand_name')\n",
    "x_test_count_encoded=pd.merge(x_test_count_encoded,avg_brand_price[['brand_name','log_price']],how='left',on='brand_name')\n",
    "x_train_count_encoded.rename(columns={'log_price':'avg_brand_price'}, inplace=True)\n",
    "x_test_count_encoded.rename(columns={'log_price':'avg_brand_price'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##category average price\n",
    "avg_cat_price=pd.DataFrame(x_train_count_encoded.groupby('category',as_index=False)['price'].mean())\n",
    "\n",
    "avg_cat_price['log_price']=np.log(avg_cat_price['price']+1)\n",
    "\n",
    "x_train_count_encoded=pd.merge(x_train_count_encoded,avg_cat_price[['category','log_price']],how='left',on='category')\n",
    "\n",
    "x_test_count_encoded=pd.merge(x_test_count_encoded,avg_cat_price[['category','log_price']],how='left',on='category')\n",
    "\n",
    "x_train_count_encoded.rename(columns={'log_price':'avg_cat_price'}, inplace=True)\n",
    "x_test_count_encoded.rename(columns={'log_price':'avg_cat_price'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##subcategory average price\n",
    "avg_subcat1_price=pd.DataFrame(x_train_count_encoded.groupby('subcategory1',as_index=False)['price'].mean())\n",
    "\n",
    "avg_subcat1_price['log_price']=np.log(avg_subcat1_price['price']+1)\n",
    "\n",
    "\n",
    "##updating average subcategory price in train and test\n",
    "x_train_count_encoded=pd.merge(x_train_count_encoded,avg_subcat1_price[['subcategory1','log_price']],how='left',on='subcategory1')\n",
    "\n",
    "x_test_count_encoded=pd.merge(x_test_count_encoded,avg_subcat1_price[['subcategory1','log_price']],how='left',on='subcategory1')\n",
    "\n",
    "x_train_count_encoded.rename(columns={'log_price':'avg_subcat1_price'}, inplace=True)\n",
    "x_test_count_encoded.rename(columns={'log_price':'avg_subcat1_price'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##subcategory average price\n",
    "avg_subcat2_price=pd.DataFrame(x_train_count_encoded.groupby('subcategory2',as_index=False)['price'].mean())\n",
    "\n",
    "avg_subcat2_price['log_price']=np.log(avg_subcat2_price['price']+1)\n",
    "\n",
    "\n",
    "##updating average subcategory price in train and test\n",
    "x_train_count_encoded=pd.merge(x_train_count_encoded,avg_subcat2_price[['subcategory2','log_price']],how='left',on='subcategory2')\n",
    "\n",
    "x_test_count_encoded=pd.merge(x_test_count_encoded,avg_subcat2_price[['subcategory2','log_price']],how='left',on='subcategory2')\n",
    "\n",
    "x_train_count_encoded.rename(columns={'log_price':'avg_subcat2_price'}, inplace=True)\n",
    "x_test_count_encoded.rename(columns={'log_price':'avg_subcat2_price'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_count_encoded['avg_brand_price'].fillna(0,inplace=True)\n",
    "x_test_count_encoded['avg_cat_price'].fillna(0,inplace=True)\n",
    "x_test_count_encoded['avg_subcat1_price'].fillna(0,inplace=True)\n",
    "x_test_count_encoded['avg_subcat2_price'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1481661, 72548)\n",
      "(3460725, 72548)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "# with the same hstack function we are concatinating a sparse matrix and a dense matirx :)\n",
    "X_TRAIN = hstack((train_name_vec,desc_tfidf_train,encoder_brand_train,x_train_count_encoded[['shipping','category_count','subcategory1_count','subcategory2_count','avg_brand_price','avg_cat_price','avg_subcat1_price','avg_subcat2_price']])).tocsr()\n",
    "print(X_TRAIN.shape)\n",
    "\n",
    "X_TEST = hstack((test_name_vec,desc_tfidf_test,encoder_brand_test,x_test_count_encoded[['shipping','category_count','subcategory1_count','subcategory2_count','avg_brand_price','avg_cat_price','avg_subcat1_price','avg_subcat2_price']])).tocsr()\n",
    "print(X_TEST.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=raw_data_zero_price_removed.log_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del(count_name)\n",
    "del(vectorizer_desc_tfidf)\n",
    "del(vect_brand)\n",
    "del(count_enc)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(avg_brand_price)\n",
    "del(avg_cat_price)\n",
    "del(avg_subcat1_price)\n",
    "del(avg_subcat2_price)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(preprocessed_name_train)\n",
    "del(preprocessed_name_test)\n",
    "del(preprocessed_description_train)\n",
    "del(preprocessed_description_test)\n",
    "del(preprocessed_brand_name_train)\n",
    "del(preprocessed_brand_name_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.7, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=16,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=200, n_jobs=-1, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=0, silent=True, subsample=1,\n",
       "             tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bytree=1, gamma=0.7,learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=16, min_child_weight=1, missing=None, n_estimators=200,\n",
    "             n_jobs=-1, random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "             seed=None, silent=True, subsample=1)\n",
    "\n",
    "print(\"Fitting Model 1\")\n",
    "xgb.fit(X_TRAIN, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xg = xgb.predict(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xg[y_pred_xg<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xg=np.exp(y_pred_xg)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['price']=y_pred_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory1</th>\n",
       "      <th>subcategory2</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>breast cancer \"i fight like a girl\" ring</td>\n",
       "      <td>1</td>\n",
       "      <td>women/jewelry/rings</td>\n",
       "      <td>Not Present</td>\n",
       "      <td>1</td>\n",
       "      <td>size 7</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>rings</td>\n",
       "      <td>10.563006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs new 7.5\"x12\" kraft bubble mailers</td>\n",
       "      <td>1</td>\n",
       "      <td>other/office supplies/shipping supplies</td>\n",
       "      <td>Not Present</td>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs new 7.5\"x12\" kraft bubble mailers lined...</td>\n",
       "      <td>other</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>shipping supplies</td>\n",
       "      <td>9.368939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                      name  item_condition_id  \\\n",
       "0        0  breast cancer \"i fight like a girl\" ring                  1   \n",
       "1        1  25 pcs new 7.5\"x12\" kraft bubble mailers                  1   \n",
       "\n",
       "                             category_name   brand_name  shipping  \\\n",
       "0                      women/jewelry/rings  Not Present         1   \n",
       "1  other/office supplies/shipping supplies  Not Present         1   \n",
       "\n",
       "                                    item_description category  \\\n",
       "0                                             size 7    women   \n",
       "1  25 pcs new 7.5\"x12\" kraft bubble mailers lined...    other   \n",
       "\n",
       "      subcategory1       subcategory2      price  \n",
       "0          jewelry              rings  10.563006  \n",
       "1  office supplies  shipping supplies   9.368939  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1=test_data[['test_id','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
